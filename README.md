# PdM MLOps Pipeline (TFX + Docker)

This project implements a **Predictive Maintenance (PdM) Machine Learning pipeline** using **TensorFlow Extended (TFX)** and a **Level 2 MLOps architecture** with Docker.  

The pipeline covers:
- âœ… Data validation (CSV + pandas)
- âœ… Preprocessing and feature engineering
- âœ… Model training
- âœ… Model validation
- âœ… Model export for serving

---

## ğŸ“‚ Project Structure

.

â”œâ”€â”€ data/ # Input datasets (CSVs)

â”œâ”€â”€ models/ # Exported models (output artifacts)

â”œâ”€â”€ tfx_pipeline/ # TFX pipeline definition

â”‚ â”œâ”€â”€ pipeline.py # Pipeline entry point

â”‚ â”œâ”€â”€ components.py # Custom components

â”œâ”€â”€ pyproject.toml # Project dependencies

â”œâ”€â”€src/model_core/

â”‚ â”œâ”€â”€ feature_dev.py # feature transformation logic in pandas

â”‚ â”œâ”€â”€ model_train_func.py # model training process

â”œâ”€â”€ uv.lock Lockfile

â””â”€â”€ Dockerfile # Docker image definition


---

## âš™ï¸ Requirements

- [Docker](https://docs.docker.com/get-docker/)  
- (Optional) Python 3.9+ and [uv](https://github.com/astral-sh/uv) if you want to run locally without Docker  

---

## ğŸ›  Build the Docker Image

From the project root:

```bash
docker build -t pdm-tfx-pipeline:latest .


â–¶ï¸ Run the Batch Pipeline

Mount data/ (input datasets) and models/ (pipeline outputs) from the host:

docker run --rm -it \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  pdm-tfx-pipeline:latest


This will run the pipeline steps:

Data Validation

Training Pipeline (Continuous Training)

Model Evaluation & Validation

Export of the validated model â†’ ./models/

ğŸ“¦ Outputs

Pipeline artifacts (trained models, metrics, transformations) are stored in ./models.

Each run produces snapshots / versions for traceability.

ğŸ— MLOps Architecture (Level 2)

The project follows a simplified CT + CD lifecycle:

Data Validated â†’ Training Pipeline (CT) â†’ Validated Model â†’ Serving (CD)


CT (Continuous Training): Each pipeline run validates input data, trains, and versions models.

CD (Continuous Delivery): The validated model is exported and ready to be deployed in a serving container.


ğŸ§ª Development & Debugging

To open a shell inside the container:

docker run --rm -it pdm-tfx-pipeline:latest /bin/bash

ğŸš€ Next Steps

Implement a serving container (FastAPI or TFX Serving) that loads latest_model from ./models.

Orchestrate with Airflow / Kubeflow for scheduled retraining.

Integrate an experiment tracker (MLflow, Vertex AI, etc.) for full lineage and monitoring.

```

![alt text](image.png)